{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "ocWZHZQNWKHE"
      },
      "outputs": [],
      "source": [
        "#  Es un framework de aprendizaje profundo que proporciona\n",
        "# herramientas para construir y entrenar redes neuronales\n",
        "import torch\n",
        "# Este módulo contiene las herramientas para definir y trabajar con capas y modelos neuronales en PyTorch\n",
        "import torch.nn as nn\n",
        "# Contiene los optimizadores para ajustar los pesos de los modelos durante el entrenamiento\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# El proceso de estandarización transforma cada característica de tal manera que tenga\n",
        "# una media de 0 y una desviación estándar de 1\n",
        "# Ayuda a que las características tengan la misma escala\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Esta función calcula la precisión de las clasificaciones proporcionadas\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEXzDGvpWqOT",
        "outputId": "705f775c-8784-4ade-ec23-a258ce249fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.000e+00 1.423e+01 1.710e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.000e+00 1.320e+01 1.780e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.000e+00 1.316e+01 2.360e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
            " ...\n",
            " [3.000e+00 1.327e+01 4.280e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
            " [3.000e+00 1.317e+01 2.590e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
            " [3.000e+00 1.413e+01 4.100e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n"
          ]
        }
      ],
      "source": [
        "# Lectura del dataset\n",
        "data = np.loadtxt(\"wine_preparado.csv\", delimiter=\",\")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Mf_9rou3W7oa"
      },
      "outputs": [],
      "source": [
        "# Seleccionar columnas independientes y dependiente\n",
        "X = data[:, 1:]\n",
        "y = data[:, 0]\n",
        "\n",
        "# Cambiamos valores de columna dependiente\n",
        "y[y == 1] = 0\n",
        "y[y == 2] = 1\n",
        "y[y == 3] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdYnb-inXYTn",
        "outputId": "3dc4aa77-09b5-4d67-e274-ad771cd54e23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
              "        1.065e+03],\n",
              "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
              "        1.050e+03],\n",
              "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
              "        1.185e+03],\n",
              "       ...,\n",
              "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
              "        8.350e+02],\n",
              "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
              "        8.400e+02],\n",
              "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
              "        5.600e+02]])"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# imprimimos caracteristicas\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuDQvyQzXZVb",
        "outputId": "7297d3f4-b5fc-4753-9b16-b6ad3a3b8089"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2.])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# imprimimos columna dependiente\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNxH4ml6XR2q",
        "outputId": "19a52ba0-dc09-44da-b472-32dcab42713e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((178, 13), (178,))"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# imprimimos dimensiones de X y y\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "eKIiuLaqXTYz"
      },
      "outputs": [],
      "source": [
        "# separamos datos de entrenamiento y de prueba, prueba en 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "axG5UU07YtII"
      },
      "outputs": [],
      "source": [
        "# Esta instancia se utilizará para calcular la media y la desviación estándar de las características\n",
        "# y luego realizar la estandarización\n",
        "scaler = StandardScaler()\n",
        "# Se ajusta y transforma el conjunto de datos de entrenamiento con la funcion fit_transform\n",
        "# Esto significa que el scaler calcula la media y la desviación estándar de cada característica\n",
        "# en X_train, y luego estandariza las características de acuerdo a estas estadísticas.\n",
        "# Después de esto, X_train contendrá las características estandarizadas.\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "# Utiliza el mismo scaler para transformar el conjunto de datos de prueba con la funcion transform\n",
        "# Esto es importante para garantizar que las características en el conjunto de prueba\n",
        "# estén estandarizadas de la misma manera que las del conjunto de entrenamiento\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# diferencia entre fit_transform y transform\n",
        "# Si estás utilizando datos de entrenamiento y necesitas ajustar el transformer y transformar\n",
        "# los datos al mismo tiempo, usa fit_transform.\n",
        "\n",
        "# Si ya has ajustado el transformer previamente y solo necesitas transformar nuevos datos\n",
        "# (por ejemplo, datos de prueba), usa transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "NmLRtFc-Y6kA"
      },
      "outputs": [],
      "source": [
        "# Este código crea una variable llamada device que almacena la cadena de caracteres 'cuda' si hay\n",
        "# un dispositivo CUDA disponible en el sistema, y 'cpu' en caso contrario.\n",
        "\n",
        "# torch.cuda.is_available(): Esta función de PyTorch verifica si hay un dispositivo CUDA disponible en el sistema\n",
        "# Después de ejecutar esta línea de código, la variable device se puede utilizar posteriormente para\n",
        "# especificar el dispositivo en el que se ejecutarán las operaciones de PyTorch. Por ejemplo, se puede\n",
        "# utilizar para enviar tensores a la GPU si device es 'cuda', o para utilizar la CPU si device es 'cpu'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# En otras palabras, esta línea de código selecciona el dispositivo adecuado ('cuda' o 'cpu')\n",
        "# en función de la disponibilidad de CUDA en el sistema.\n",
        "\n",
        "# para aplicaciones que requieren un alto rendimiento en operaciones matemáticas intensivas,\n",
        "# como el entrenamiento de modelos de aprendizaje profundo, CUDA y las GPU son la elección\n",
        "# preferida debido a su capacidad de procesamiento masivo en paralelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "37owVwMPZFmL"
      },
      "outputs": [],
      "source": [
        "# Convierte el conjunto de datos en un tensor de PyTorch. torch.tensor() se utiliza para crear un\n",
        "# tensor a partir de un array. dtype=torch.float o int64 especifica que se desea que el tensor resultante\n",
        "# tenga tipo de datos float o int64. .to(device) envía el tensor resultante al dispositivo especificado\n",
        "# por la variable device.\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.int64).to(device)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.int64).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "LG3RzsfMabYe"
      },
      "outputs": [],
      "source": [
        "# Define una nueva clase llamada SimpleClassifier que hereda de nn.Module\n",
        "class SimpleClassifier(nn.Module):\n",
        "  # Este es el método constructor de la clase SimpleClassifier. Toma dos argumentos:\n",
        "  # in_features, que representa el número de características de entrada al modelo, y out_features,\n",
        "  # que representa el número de clases de salida.\n",
        "  def __init__(self, in_features, out_features):\n",
        "    # Llama al constructor de la clase base nn.Module, lo que inicializa la clase base y establece\n",
        "    # el estado interno del modelo.\n",
        "    super().__init__()\n",
        "    # Define la primera capa lineal (nn.Linear) del modelo. Esta capa tiene in_features entradas y 120 salidas.\n",
        "    # La capa lineal aplica una transformación lineal a los datos de entrada.\n",
        "    self.layer_1 = nn.Linear(in_features,120)\n",
        "    #  Define la segunda capa lineal del modelo. Esta capa toma 120 entradas de la capa anterior y produce\n",
        "    # 10 salidas.\n",
        "    self.layer_2 = nn.Linear(120,10)\n",
        "    # Define la tercera capa lineal del modelo. Esta capa toma 10 entradas de la capa anterior y produce\n",
        "    # out_features salidas, que es el número de clases de salida\n",
        "    self.layer_3 = nn.Linear(10,out_features)\n",
        "\n",
        "  # Este método define cómo se realiza la propagación hacia adelante en el modelo.\n",
        "  # Toma un tensor de entrada x y devuelve un tensor de salida.\n",
        "  def forward(self, x):\n",
        "    # Define la secuencia de operaciones que se aplican al tensor de entrada x. Primero se pasa x\n",
        "    # a través de layer_1, luego se aplica una función de activación (por defecto, lineal)\n",
        "    # a la salida de layer_1. El resultado se pasa a layer_2, y luego a layer_3.\n",
        "    # Esto representa una arquitectura de red neuronal feedforward de tres capas.\n",
        "    x = self.layer_3(self.layer_2(self.layer_1(x)))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "SwINKo-xbx1C"
      },
      "outputs": [],
      "source": [
        "# Calcula el número de características de entrada (in_features) del conjunto de\n",
        "# datos de entrenamiento X_train. X_train.shape[1] devuelve la longitud de la segunda dimensión\n",
        "# de X_train, que es el número de características.\n",
        "in_features = X_train.shape[1]\n",
        "#  Calcula el número de clases de salida (num_classes) del conjunto de etiquetas y. set(y)\n",
        "# devuelve un conjunto único de clases en y, y len() cuenta cuántas clases únicas hay en total.\n",
        "num_classes = len(set(y))\n",
        "\n",
        "# Inicializa un objeto de la clase SimpleClassifier con in_features como el número de características de entrada\n",
        "# y num_classes como el número de clases de salida. Luego, se envía el modelo al dispositivo especificado por\n",
        "# la variable device.\n",
        "model = SimpleClassifier(in_features,num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "kINezU47cVr_"
      },
      "outputs": [],
      "source": [
        "# Define la función de pérdida que se utilizará para calcular\n",
        "# el error del modelo durante el entrenamiento. nn.CrossEntropyLoss()\n",
        "# es comúnmente utilizada en problemas de clasificación multiclase\n",
        "# Esta función combina una capa Softmax y la función de pérdida de\n",
        "# entropía cruzada logarítmica, que es adecuada para problemas de\n",
        "# clasificación en los que se espera que cada muestra pertenezca a una sola clase.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Define el optimizador que se utilizará para ajustar los pesos del modelo durante\n",
        "# el entrenamiento. En este caso, se utiliza el descenso de gradiente estocástico\n",
        "# (SGD). model.parameters() devuelve los parámetros entrenables del modelo, es decir,\n",
        "# los pesos de las capas lineales. El parámetro lr=0.01 especifica la tasa de aprendizaje,\n",
        "# que controla el tamaño de los pasos de actualización de los pesos durante el entrenamiento.\n",
        "# Un valor pequeño de la tasa de aprendizaje generalmente hace que el entrenamiento sea\n",
        "# más lento pero más estable.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v87WZU9CeNgP",
        "outputId": "94659a21-e9b0-4d98-eeb3-690d0cd62925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/1000], Loss: 0.8533, Accuracy: 0.8028\n",
            "Epoch [20/1000], Loss: 0.7160, Accuracy: 0.9014\n",
            "Epoch [30/1000], Loss: 0.6053, Accuracy: 0.9225\n",
            "Epoch [40/1000], Loss: 0.5145, Accuracy: 0.9507\n",
            "Epoch [50/1000], Loss: 0.4400, Accuracy: 0.9507\n",
            "Epoch [60/1000], Loss: 0.3792, Accuracy: 0.9507\n",
            "Epoch [70/1000], Loss: 0.3299, Accuracy: 0.9577\n",
            "Epoch [80/1000], Loss: 0.2901, Accuracy: 0.9577\n",
            "Epoch [90/1000], Loss: 0.2578, Accuracy: 0.9648\n",
            "Epoch [100/1000], Loss: 0.2314, Accuracy: 0.9718\n",
            "Epoch [110/1000], Loss: 0.2097, Accuracy: 0.9859\n",
            "Epoch [120/1000], Loss: 0.1916, Accuracy: 0.9859\n",
            "Epoch [130/1000], Loss: 0.1763, Accuracy: 0.9859\n",
            "Epoch [140/1000], Loss: 0.1633, Accuracy: 0.9859\n",
            "Epoch [150/1000], Loss: 0.1522, Accuracy: 0.9859\n",
            "Epoch [160/1000], Loss: 0.1425, Accuracy: 0.9930\n",
            "Epoch [170/1000], Loss: 0.1339, Accuracy: 0.9930\n",
            "Epoch [180/1000], Loss: 0.1264, Accuracy: 0.9930\n",
            "Epoch [190/1000], Loss: 0.1197, Accuracy: 0.9930\n",
            "Epoch [200/1000], Loss: 0.1137, Accuracy: 0.9930\n",
            "Epoch [210/1000], Loss: 0.1083, Accuracy: 0.9930\n",
            "Epoch [220/1000], Loss: 0.1034, Accuracy: 0.9930\n",
            "Epoch [230/1000], Loss: 0.0990, Accuracy: 0.9930\n",
            "Epoch [240/1000], Loss: 0.0949, Accuracy: 0.9930\n",
            "Epoch [250/1000], Loss: 0.0912, Accuracy: 0.9930\n",
            "Epoch [260/1000], Loss: 0.0877, Accuracy: 0.9930\n",
            "Epoch [270/1000], Loss: 0.0845, Accuracy: 0.9930\n",
            "Epoch [280/1000], Loss: 0.0816, Accuracy: 0.9930\n",
            "Epoch [290/1000], Loss: 0.0788, Accuracy: 0.9930\n",
            "Epoch [300/1000], Loss: 0.0762, Accuracy: 0.9930\n",
            "Epoch [310/1000], Loss: 0.0738, Accuracy: 0.9930\n",
            "Epoch [320/1000], Loss: 0.0716, Accuracy: 0.9930\n",
            "Epoch [330/1000], Loss: 0.0694, Accuracy: 0.9930\n",
            "Epoch [340/1000], Loss: 0.0674, Accuracy: 0.9930\n",
            "Epoch [350/1000], Loss: 0.0656, Accuracy: 0.9930\n",
            "Epoch [360/1000], Loss: 0.0638, Accuracy: 0.9930\n",
            "Epoch [370/1000], Loss: 0.0621, Accuracy: 0.9930\n",
            "Epoch [380/1000], Loss: 0.0605, Accuracy: 0.9930\n",
            "Epoch [390/1000], Loss: 0.0590, Accuracy: 0.9930\n",
            "Epoch [400/1000], Loss: 0.0575, Accuracy: 0.9930\n",
            "Epoch [410/1000], Loss: 0.0562, Accuracy: 0.9930\n",
            "Epoch [420/1000], Loss: 0.0549, Accuracy: 0.9930\n",
            "Epoch [430/1000], Loss: 0.0536, Accuracy: 0.9930\n",
            "Epoch [440/1000], Loss: 0.0524, Accuracy: 0.9930\n",
            "Epoch [450/1000], Loss: 0.0513, Accuracy: 0.9930\n",
            "Epoch [460/1000], Loss: 0.0502, Accuracy: 0.9930\n",
            "Epoch [470/1000], Loss: 0.0491, Accuracy: 0.9930\n",
            "Epoch [480/1000], Loss: 0.0481, Accuracy: 0.9930\n",
            "Epoch [490/1000], Loss: 0.0472, Accuracy: 0.9930\n",
            "Epoch [500/1000], Loss: 0.0463, Accuracy: 0.9930\n",
            "Epoch [510/1000], Loss: 0.0454, Accuracy: 0.9930\n",
            "Epoch [520/1000], Loss: 0.0445, Accuracy: 0.9930\n",
            "Epoch [530/1000], Loss: 0.0437, Accuracy: 0.9930\n",
            "Epoch [540/1000], Loss: 0.0429, Accuracy: 0.9930\n",
            "Epoch [550/1000], Loss: 0.0421, Accuracy: 0.9930\n",
            "Epoch [560/1000], Loss: 0.0414, Accuracy: 0.9930\n",
            "Epoch [570/1000], Loss: 0.0407, Accuracy: 0.9930\n",
            "Epoch [580/1000], Loss: 0.0400, Accuracy: 0.9930\n",
            "Epoch [590/1000], Loss: 0.0393, Accuracy: 1.0000\n",
            "Epoch [600/1000], Loss: 0.0387, Accuracy: 1.0000\n",
            "Epoch [610/1000], Loss: 0.0380, Accuracy: 1.0000\n",
            "Epoch [620/1000], Loss: 0.0374, Accuracy: 1.0000\n",
            "Epoch [630/1000], Loss: 0.0369, Accuracy: 1.0000\n",
            "Epoch [640/1000], Loss: 0.0363, Accuracy: 1.0000\n",
            "Epoch [650/1000], Loss: 0.0357, Accuracy: 1.0000\n",
            "Epoch [660/1000], Loss: 0.0352, Accuracy: 1.0000\n",
            "Epoch [670/1000], Loss: 0.0347, Accuracy: 1.0000\n",
            "Epoch [680/1000], Loss: 0.0342, Accuracy: 1.0000\n",
            "Epoch [690/1000], Loss: 0.0337, Accuracy: 1.0000\n",
            "Epoch [700/1000], Loss: 0.0332, Accuracy: 1.0000\n",
            "Epoch [710/1000], Loss: 0.0327, Accuracy: 1.0000\n",
            "Epoch [720/1000], Loss: 0.0323, Accuracy: 1.0000\n",
            "Epoch [730/1000], Loss: 0.0319, Accuracy: 1.0000\n",
            "Epoch [740/1000], Loss: 0.0314, Accuracy: 1.0000\n",
            "Epoch [750/1000], Loss: 0.0310, Accuracy: 1.0000\n",
            "Epoch [760/1000], Loss: 0.0306, Accuracy: 1.0000\n",
            "Epoch [770/1000], Loss: 0.0302, Accuracy: 1.0000\n",
            "Epoch [780/1000], Loss: 0.0298, Accuracy: 1.0000\n",
            "Epoch [790/1000], Loss: 0.0294, Accuracy: 1.0000\n",
            "Epoch [800/1000], Loss: 0.0291, Accuracy: 1.0000\n",
            "Epoch [810/1000], Loss: 0.0287, Accuracy: 1.0000\n",
            "Epoch [820/1000], Loss: 0.0284, Accuracy: 1.0000\n",
            "Epoch [830/1000], Loss: 0.0280, Accuracy: 1.0000\n",
            "Epoch [840/1000], Loss: 0.0277, Accuracy: 1.0000\n",
            "Epoch [850/1000], Loss: 0.0274, Accuracy: 1.0000\n",
            "Epoch [860/1000], Loss: 0.0270, Accuracy: 1.0000\n",
            "Epoch [870/1000], Loss: 0.0267, Accuracy: 1.0000\n",
            "Epoch [880/1000], Loss: 0.0264, Accuracy: 1.0000\n",
            "Epoch [890/1000], Loss: 0.0261, Accuracy: 1.0000\n",
            "Epoch [900/1000], Loss: 0.0258, Accuracy: 1.0000\n",
            "Epoch [910/1000], Loss: 0.0256, Accuracy: 1.0000\n",
            "Epoch [920/1000], Loss: 0.0253, Accuracy: 1.0000\n",
            "Epoch [930/1000], Loss: 0.0250, Accuracy: 1.0000\n",
            "Epoch [940/1000], Loss: 0.0247, Accuracy: 1.0000\n",
            "Epoch [950/1000], Loss: 0.0245, Accuracy: 1.0000\n",
            "Epoch [960/1000], Loss: 0.0242, Accuracy: 1.0000\n",
            "Epoch [970/1000], Loss: 0.0240, Accuracy: 1.0000\n",
            "Epoch [980/1000], Loss: 0.0237, Accuracy: 1.0000\n",
            "Epoch [990/1000], Loss: 0.0235, Accuracy: 1.0000\n",
            "Epoch [1000/1000], Loss: 0.0232, Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Define el número total de épocas (iteraciones) para entrenar el modelo.\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # Pone el modelo en modo de entrenamiento. Esto es importante para ciertas capas,\n",
        "  # como las capas de dropout o de normalización, que se comportan de manera diferente\n",
        "  # durante el entrenamiento y la evaluación\n",
        "  model.train()\n",
        "\n",
        "  # Realiza una pasada hacia adelante (forward pass) del modelo utilizando los\n",
        "  # datos de entrenamiento X_train_tensor y obtiene las salidas predichas\n",
        "  outputs = model(X_train_tensor)\n",
        "  # Calcula la pérdida del modelo comparando las salidas predichas con las etiquetas\n",
        "  # reales usando la función de pérdida definida anteriormente (criterion)\n",
        "  loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "  # Calcula las etiquetas predichas tomando el índice del valor máximo en las salidas predichas.\n",
        "  # Estas etiquetas se utilizarán para calcular la precisión del modelo\n",
        "  _, predicted_labels = torch.max(outputs,1)\n",
        "  # Calcula el número de predicciones correctas comparando las etiquetas predichas con las etiquetas reales\n",
        "  correct_predictions = (predicted_labels == y_train_tensor).sum().item()\n",
        "\n",
        "  # Calcula el número total de muestras en el conjunto de entrenamiento\n",
        "  total_samples = len(y_train_tensor)\n",
        "  # Calcula la precisión del modelo dividiendo el número de predicciones\n",
        "  # correctas por el número total de muestras\n",
        "  acc = correct_predictions / total_samples\n",
        "\n",
        "  # Reinicia los gradientes de todos los parámetros del modelo a cero. Esto es necesario porque\n",
        "  # PyTorch acumula los gradientes en cada iteración de retropropagación\n",
        "  optimizer.zero_grad()\n",
        "  # Realiza la retropropagación (backpropagation) para calcular los gradientes de los parámetros\n",
        "  # del modelo con respecto a la función de pérdida\n",
        "  loss.backward()\n",
        "  #Actualiza los parámetros del modelo utilizando el optimizador configurado previamente\n",
        "  optimizer.step()\n",
        "\n",
        "  # Imprime el progreso del entrenamiento cada 10 épocas.\n",
        "  if (epoch+1)%10==0:\n",
        "    # Imprime el número de época actual, la pérdida actual y la precisión del modelo en el conjunto de entrenamiento.\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN3rftE-fYvF",
        "outputId": "11f3746c-c065-4bb0-8ed6-709a07c38f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicciones y datos reales de prueba:\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 1, Etiqueta verdadera: 1.0\n",
            "Predicción: 2, Etiqueta verdadera: 2.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Predicción: 0, Etiqueta verdadera: 0.0\n",
            "Precisión total: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Pone el modelo en modo de evaluación. Esto es importante para ciertas capas,\n",
        "# como las capas de dropout o de normalización, que se comportan de manera diferente\n",
        "# durante la evaluación que durante el entrenamiento\n",
        "model.eval()\n",
        "\n",
        "# Realiza una pasada hacia adelante (forward pass) del modelo utilizando los datos de\n",
        "# prueba X_test_tensor y obtiene las salidas predichas\n",
        "outputs = model(X_test_tensor)\n",
        "# Calcula las etiquetas predichas tomando el índice del valor máximo en las salidas predichas\n",
        "_, predicted = torch.max(outputs,1)\n",
        "\n",
        "  # Imprimir todas las predicciones y los datos reales de prueba\n",
        "print(\"Predicciones y datos reales de prueba:\")\n",
        "\n",
        "# Itera sobre cada muestra en el conjunto de datos de prueba\n",
        "for i in range(len(X_test)):\n",
        "  # Obtiene la etiqueta predicha para la muestra actual\n",
        "  predicted_label = predicted[i].item()\n",
        "  # Obtiene la etiqueta verdadera para la muestra actual\n",
        "  true_label = y_test[i]\n",
        "  # Imprime la predicción y la etiqueta verdadera para la muestra actual\n",
        "  print(f\"Predicción: {predicted_label}, Etiqueta verdadera: {true_label}\")\n",
        "\n",
        "# Calcular la precisión total\n",
        "total_accuracy = accuracy_score(y_test, predicted.cpu().numpy())\n",
        "\n",
        "# Convertir la precisión total a porcentaje\n",
        "total_accuracy_percent = total_accuracy * 100\n",
        "\n",
        "# Imprimir el porcentaje total de precisión\n",
        "print(f\"Precisión total: {total_accuracy_percent:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
